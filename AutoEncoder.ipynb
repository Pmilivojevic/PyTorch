{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pmilivojevic/PyTorch/blob/main/AutoEncoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9mfmr1A2Bdcu"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.nn.modules.activation import ReLU\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.ao.nn.quantized.modules.conv import ConvTranspose2d\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6sgPCoLjCQy-",
        "outputId": "383e1369-ac9f-4370-bffe-35ca82bdf3c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /content/drive/MyDrive/Colab Notebooks/Dataset/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 170498071/170498071 [00:02<00:00, 66711358.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting /content/drive/MyDrive/Colab Notebooks/Dataset/cifar-10-python.tar.gz to /content/drive/MyDrive/Colab Notebooks/Dataset\n"
          ]
        }
      ],
      "source": [
        "transform = transforms.ToTensor()\n",
        "cifar10_dataset = datasets.CIFAR10(\n",
        "    root='/content/drive/MyDrive/Colab Notebooks/Dataset',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")\n",
        "data_loader = torch.utils.data.DataLoader(\n",
        "    dataset=cifar10_dataset,\n",
        "    batch_size=64,\n",
        "    shuffle=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NM0g3cBjECqT",
        "outputId": "c83e5a54-4f77-4b7f-faa0-454c2bc152bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.) tensor(1.)\n"
          ]
        }
      ],
      "source": [
        "dataiter = iter(data_loader)\n",
        "images, labels = next(dataiter)\n",
        "print(torch.min(images), torch.max(images))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PLAMOID8Eovc"
      },
      "outputs": [],
      "source": [
        "\n",
        "class AutoEncoderL(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(AutoEncoderL, self).__init__()\n",
        "\n",
        "    self.encoder = nn.Sequential(\n",
        "        nn.Linear(3*32*32, 1024),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(1024, 256),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(256, 64),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(64, 32),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(32, 9)\n",
        "    )\n",
        "\n",
        "    self.decoder = nn.Sequential(\n",
        "        nn.Linear(9, 32),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(32, 64),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(64, 256),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(256, 1024),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(1024, 3*32*32),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    enc = self.encoder(x)\n",
        "    dec = self.decoder(enc)\n",
        "    return dec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lSqScNfdzhad"
      },
      "outputs": [],
      "source": [
        "class AutoEncoderC(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    self.encoder = nn.Sequential(\n",
        "        nn.Conv2d(3, 16, 3, 2, 1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(16, 32, 3, 2, 1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(32, 64, 3, 2, 1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(64, 128, 4)\n",
        "    )\n",
        "\n",
        "    self.decoder = nn.Sequential(\n",
        "        nn.ConvTranspose2d(128, 64, 4),\n",
        "        nn.ReLU(),\n",
        "        nn.ConvTranspose2d(64, 32, 3, 2, 1, 1),\n",
        "        nn.ReLU(),\n",
        "        nn.ConvTranspose2d(32, 16, 3, 2, 1, 1),\n",
        "        nn.ReLU(),\n",
        "        nn.ConvTranspose2d(16, 3, 3, 2, 1, 1),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    encoded = self.encoder(x)\n",
        "    decoded = self.decoder(encoded)\n",
        "\n",
        "    return decoded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N-yy9N2JKYdE"
      },
      "outputs": [],
      "source": [
        "model = AutoEncoderC().to(device)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "6snX4TOtOHDR",
        "outputId": "8ca76d79-3a3d-4ca9-b460-fa11a760e57d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1, Loss: 0.0178\n",
            "Epoch: 2, Loss: 0.0146\n",
            "Epoch: 3, Loss: 0.0104\n",
            "Epoch: 4, Loss: 0.0096\n",
            "Epoch: 5, Loss: 0.0086\n",
            "Epoch: 6, Loss: 0.0080\n",
            "Epoch: 7, Loss: 0.0090\n",
            "Epoch: 8, Loss: 0.0075\n",
            "Epoch: 9, Loss: 0.0061\n",
            "Epoch: 10, Loss: 0.0079\n",
            "Epoch: 11, Loss: 0.0064\n",
            "Epoch: 12, Loss: 0.0050\n",
            "Epoch: 13, Loss: 0.0061\n",
            "Epoch: 14, Loss: 0.0060\n",
            "Epoch: 15, Loss: 0.0064\n",
            "Epoch: 16, Loss: 0.0054\n",
            "Epoch: 17, Loss: 0.0060\n",
            "Epoch: 18, Loss: 0.0059\n",
            "Epoch: 19, Loss: 0.0045\n",
            "Epoch: 20, Loss: 0.0049\n",
            "Epoch: 21, Loss: 0.0050\n",
            "Epoch: 22, Loss: 0.0040\n",
            "Epoch: 23, Loss: 0.0056\n",
            "Epoch: 24, Loss: 0.0062\n",
            "Epoch: 25, Loss: 0.0059\n",
            "Epoch: 26, Loss: 0.0049\n",
            "Epoch: 27, Loss: 0.0052\n",
            "Epoch: 28, Loss: 0.0048\n",
            "Epoch: 29, Loss: 0.0061\n",
            "Epoch: 30, Loss: 0.0052\n",
            "Epoch: 31, Loss: 0.0050\n",
            "Epoch: 32, Loss: 0.0063\n",
            "Epoch: 33, Loss: 0.0050\n",
            "Epoch: 34, Loss: 0.0054\n",
            "Epoch: 35, Loss: 0.0048\n",
            "Epoch: 36, Loss: 0.0052\n",
            "Epoch: 37, Loss: 0.0048\n",
            "Epoch: 38, Loss: 0.0050\n",
            "Epoch: 39, Loss: 0.0053\n",
            "Epoch: 40, Loss: 0.0045\n",
            "Epoch: 41, Loss: 0.0050\n",
            "Epoch: 42, Loss: 0.0054\n",
            "Epoch: 43, Loss: 0.0051\n",
            "Epoch: 44, Loss: 0.0055\n",
            "Epoch: 45, Loss: 0.0057\n",
            "Epoch: 46, Loss: 0.0051\n",
            "Epoch: 47, Loss: 0.0047\n",
            "Epoch: 48, Loss: 0.0049\n",
            "Epoch: 49, Loss: 0.0053\n",
            "Epoch: 50, Loss: 0.0053\n",
            "Epoch: 51, Loss: 0.0051\n",
            "Epoch: 52, Loss: 0.0061\n",
            "Epoch: 53, Loss: 0.0050\n",
            "Epoch: 54, Loss: 0.0048\n",
            "Epoch: 55, Loss: 0.0042\n",
            "Epoch: 56, Loss: 0.0049\n",
            "Epoch: 57, Loss: 0.0069\n",
            "Epoch: 58, Loss: 0.0056\n",
            "Epoch: 59, Loss: 0.0045\n",
            "Epoch: 60, Loss: 0.0059\n",
            "Epoch: 61, Loss: 0.0058\n",
            "Epoch: 62, Loss: 0.0053\n",
            "Epoch: 63, Loss: 0.0052\n",
            "Epoch: 64, Loss: 0.0052\n",
            "Epoch: 65, Loss: 0.0048\n",
            "Epoch: 66, Loss: 0.0049\n",
            "Epoch: 67, Loss: 0.0044\n",
            "Epoch: 68, Loss: 0.0047\n",
            "Epoch: 69, Loss: 0.0045\n",
            "Epoch: 70, Loss: 0.0063\n",
            "Epoch: 71, Loss: 0.0056\n",
            "Epoch: 72, Loss: 0.0049\n",
            "Epoch: 73, Loss: 0.0050\n",
            "Epoch: 74, Loss: 0.0049\n",
            "Epoch: 75, Loss: 0.0049\n",
            "Epoch: 76, Loss: 0.0043\n",
            "Epoch: 77, Loss: 0.0050\n",
            "Epoch: 78, Loss: 0.0054\n",
            "Epoch: 79, Loss: 0.0060\n",
            "Epoch: 80, Loss: 0.0055\n",
            "Epoch: 81, Loss: 0.0057\n",
            "Epoch: 82, Loss: 0.0038\n",
            "Epoch: 83, Loss: 0.0059\n",
            "Epoch: 84, Loss: 0.0046\n",
            "Epoch: 85, Loss: 0.0046\n",
            "Epoch: 86, Loss: 0.0054\n",
            "Epoch: 87, Loss: 0.0061\n",
            "Epoch: 88, Loss: 0.0061\n",
            "Epoch: 89, Loss: 0.0043\n",
            "Epoch: 90, Loss: 0.0048\n",
            "Epoch: 91, Loss: 0.0048\n",
            "Epoch: 92, Loss: 0.0042\n",
            "Epoch: 93, Loss: 0.0042\n",
            "Epoch: 94, Loss: 0.0051\n",
            "Epoch: 95, Loss: 0.0054\n",
            "Epoch: 96, Loss: 0.0061\n",
            "Epoch: 97, Loss: 0.0047\n",
            "Epoch: 98, Loss: 0.0045\n",
            "Epoch: 99, Loss: 0.0046\n",
            "Epoch: 100, Loss: 0.0058\n",
            "Epoch: 101, Loss: 0.0046\n",
            "Epoch: 102, Loss: 0.0062\n",
            "Epoch: 103, Loss: 0.0066\n",
            "Epoch: 104, Loss: 0.0057\n",
            "Epoch: 105, Loss: 0.0043\n",
            "Epoch: 106, Loss: 0.0066\n",
            "Epoch: 107, Loss: 0.0048\n",
            "Epoch: 108, Loss: 0.0051\n",
            "Epoch: 109, Loss: 0.0054\n",
            "Epoch: 110, Loss: 0.0048\n",
            "Epoch: 111, Loss: 0.0045\n",
            "Epoch: 112, Loss: 0.0044\n",
            "Epoch: 113, Loss: 0.0052\n",
            "Epoch: 114, Loss: 0.0054\n",
            "Epoch: 115, Loss: 0.0046\n",
            "Epoch: 116, Loss: 0.0057\n",
            "Epoch: 117, Loss: 0.0045\n",
            "Epoch: 118, Loss: 0.0050\n",
            "Epoch: 119, Loss: 0.0052\n",
            "Epoch: 120, Loss: 0.0044\n",
            "Epoch: 121, Loss: 0.0052\n",
            "Epoch: 122, Loss: 0.0047\n",
            "Epoch: 123, Loss: 0.0040\n",
            "Epoch: 124, Loss: 0.0046\n",
            "Epoch: 125, Loss: 0.0047\n",
            "Epoch: 126, Loss: 0.0048\n",
            "Epoch: 127, Loss: 0.0044\n",
            "Epoch: 128, Loss: 0.0045\n",
            "Epoch: 129, Loss: 0.0045\n",
            "Epoch: 130, Loss: 0.0054\n",
            "Epoch: 131, Loss: 0.0061\n",
            "Epoch: 132, Loss: 0.0058\n",
            "Epoch: 133, Loss: 0.0059\n",
            "Epoch: 134, Loss: 0.0043\n",
            "Epoch: 135, Loss: 0.0054\n",
            "Epoch: 136, Loss: 0.0061\n",
            "Epoch: 137, Loss: 0.0060\n",
            "Epoch: 138, Loss: 0.0043\n",
            "Epoch: 139, Loss: 0.0069\n",
            "Epoch: 140, Loss: 0.0043\n",
            "Epoch: 141, Loss: 0.0049\n",
            "Epoch: 142, Loss: 0.0052\n",
            "Epoch: 143, Loss: 0.0049\n",
            "Epoch: 144, Loss: 0.0048\n",
            "Epoch: 145, Loss: 0.0058\n",
            "Epoch: 146, Loss: 0.0050\n",
            "Epoch: 147, Loss: 0.0055\n",
            "Epoch: 148, Loss: 0.0044\n",
            "Epoch: 149, Loss: 0.0046\n",
            "Epoch: 150, Loss: 0.0040\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 180\n",
        "outputs = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  for batch_ind, (image,_) in enumerate(data_loader):\n",
        "    # image = image.to(device).reshape(image.shape[0], -1)\n",
        "\n",
        "    recon = model(image)\n",
        "    loss = criterion(recon, image)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  print(f'Epoch: {epoch+1}, Loss: {loss.item():.4f}')\n",
        "  outputs.append((epoch, image, recon))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uhit0NajSAev"
      },
      "outputs": [],
      "source": [
        "for k in range(0, num_epochs, 6):\n",
        "  # plt.figure(figsize=(9,2))\n",
        "\n",
        "  imgs = outputs[k][1].cpu().detach().numpy()\n",
        "  recons = outputs[k][2].cpu().detach().numpy()\n",
        "\n",
        "  for i, img in enumerate(imgs):\n",
        "    if i >= 9: break\n",
        "    plt.subplot(2, 9, i+1)\n",
        "    img = img.reshape(-1, 32, 32).transpose(1, 2, 0)\n",
        "    plt.imshow(img)\n",
        "\n",
        "  for i, rec in enumerate(recons):\n",
        "    if i >= 9: break\n",
        "    plt.subplot(2, 9, 9+i+1)\n",
        "    rec = rec.reshape(-1, 32, 32).transpose(1, 2, 0)\n",
        "    plt.imshow(rec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t0HHyVV37vbO"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMniNMjj7Bfo9NEQvfdmEtQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}