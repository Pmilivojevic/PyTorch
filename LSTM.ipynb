{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1jtsO_FzWMntGjUa4Mykxsck4GIN9XSan",
      "authorship_tag": "ABX9TyPSlyEFUQWUzt+ozVH2S+GB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pmilivojevic/PyTorch/blob/main/LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYyXr1E6JWLy",
        "outputId": "75729130-8732-4461-e1ca-089205122035"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.3.7-py3-none-any.whl (235 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/235.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.9/235.5 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/235.5 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.3.7\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import string\n",
        "import random\n",
        "# !pip install unidecode\n",
        "import unidecode\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_characters = string.printable\n",
        "n_caracters = len(all_characters)\n",
        "\n",
        "fl = unidecode.unidecode(\n",
        "    open(\n",
        "        '/content/drive/MyDrive/ColabNotebooks/PyTorch/Dataset/names.txt'\n",
        "    ).read()\n",
        ")"
      ],
      "metadata": {
        "id": "akh53_qbJlQ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
        "    super().__init__()\n",
        "\n",
        "    self.hidden_size = hidden_size\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    self.embed = nn.Embedding(input_size, hidden_size)\n",
        "    self.lstm = nn.LSTM(hidden_size, hidden_size, num_layers, batch_first=True)\n",
        "    self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "  def forward(self, x, hidden, cell):\n",
        "    out = self.embed(x)\n",
        "    out, (hidden, cell) = self.lstm(out.unsqueeze(1), (hidden, cell))\n",
        "    out = self.fc(out.reshape(out.shape[0], -1))\n",
        "\n",
        "    return out, (hidden, cell)\n",
        "\n",
        "  def init_hidden(self, batch_size):\n",
        "    hidden = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device)\n",
        "    cell = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device)\n",
        "\n",
        "    return hidden, cell"
      ],
      "metadata": {
        "id": "d9V-w4n-ORnI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator():\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    self.chunk_len = 250\n",
        "    self.num_epochs = 5000\n",
        "    self.batch_size = 1\n",
        "    self.print_every = 50\n",
        "    self.hidden_size = 256\n",
        "    self.num_layers = 2\n",
        "    self.lr = 0.003\n",
        "\n",
        "  def char_tensor(self, string):\n",
        "    tensor = torch.zeros(len(string)).long()\n",
        "\n",
        "    for c in range(len(string)):\n",
        "      tensor[c] = all_characters.index(string[c])\n",
        "\n",
        "    return tensor\n",
        "\n",
        "  def get_rand_batch(self):\n",
        "    start_idx = random.randint(0, len(fl) - self.chunk_len)\n",
        "    end_idx = start_idx + self.chunk_len + 1\n",
        "\n",
        "    text_str = fl[start_idx:end_idx]\n",
        "    text_input = torch.zeros(self.batch_size, self.chunk_len)\n",
        "    text_target = torch.zeros(self.batch_size, self.chunk_len)\n",
        "\n",
        "    for i in range(self.batch_size):\n",
        "      text_input[i,:] = self.char_tensor(text_str[:-1])\n",
        "      text_target[i,:] = self.char_tensor(text_str[1:])\n",
        "\n",
        "    return text_input.long(), text_target.long()\n",
        "\n",
        "  def generate(self, initial_str=\"A\", predict_len=100, temperature=0.85):\n",
        "        hidden, cell = self.rnn.init_hidden(batch_size=self.batch_size)\n",
        "        initial_input = self.char_tensor(initial_str)\n",
        "        predicted = initial_str\n",
        "\n",
        "        for p in range(len(initial_str) - 1):\n",
        "            _, (hidden, cell) = self.rnn(\n",
        "                initial_input[p].view(1).to(device), hidden, cell\n",
        "            )\n",
        "\n",
        "        last_char = initial_input[-1]\n",
        "\n",
        "        for p in range(predict_len):\n",
        "            output, (hidden, cell) = self.rnn(\n",
        "                last_char.view(1).to(device), hidden, cell\n",
        "            )\n",
        "            output_dist = output.data.view(-1).div(temperature).exp()\n",
        "            top_char = torch.multinomial(output_dist, 1)[0]\n",
        "            predicted_char = all_characters[top_char]\n",
        "            predicted += predicted_char\n",
        "            last_char = self.char_tensor(predicted_char)\n",
        "\n",
        "        return predicted\n",
        "\n",
        "  def train(self):\n",
        "    self.rnn = RNN(\n",
        "        n_caracters,\n",
        "        self.hidden_size,\n",
        "        self.num_layers,\n",
        "        n_caracters\n",
        "    ).to(device)\n",
        "\n",
        "    optimizer = torch.optim.Adam(self.rnn.parameters(), lr=self.lr)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    writer = SummaryWriter(f'runs/names0')\n",
        "\n",
        "    print('=> Start training!!!!')\n",
        "\n",
        "    for epoch in range(1, self.num_epochs + 1):\n",
        "      input, target = self.get_rand_batch()\n",
        "      hidden, cell = self.rnn.init_hidden(self.batch_size)\n",
        "\n",
        "      self.rnn.zero_grad()\n",
        "      loss = 0\n",
        "      input = input.to(device)\n",
        "      target = target.to(device)\n",
        "\n",
        "      for c in range(self.chunk_len):\n",
        "        out, (hidden, cell) = self.rnn(input[:,c], hidden, cell)\n",
        "        loss += criterion(out, target[:,c])\n",
        "\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      loss = loss.item() / self.chunk_len\n",
        "\n",
        "      if epoch % self.print_every == 0:\n",
        "        print(f'Loss: {loss}')\n",
        "        pred = self.generate()\n",
        "        if pred not in fl:\n",
        "          print(pred)\n",
        "\n",
        "      writer.add_scalar('Training loss', loss, global_step=epoch)"
      ],
      "metadata": {
        "id": "PRGCIMiVSOza"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gennames = Generator()\n",
        "gennames.train()"
      ],
      "metadata": {
        "id": "QX5ZhwIsi1Rv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import spacy\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "# !python -m spacy download de_core_news_sm\n",
        "# !pip install -U torchtext==0.6\n",
        "from torchtext.data import Field, TabularDataset, BucketIterator, Iterator\n",
        "from torchtext.datasets import Multi30k\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "pTg2wkqZwDJz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "english_txt = open(\n",
        "    '/content/drive/MyDrive/ColabNotebooks/PyTorch/Datasets/europarl-v7.de-en.en',\n",
        "    encoding='utf8'\n",
        ").read().split('\\n')\n",
        "\n",
        "german_txt = open(\n",
        "    '/content/drive/MyDrive/ColabNotebooks/PyTorch/Datasets/europarl-v7.de-en.de',\n",
        "    encoding='utf8'\n",
        ").read().split('\\n')"
      ],
      "metadata": {
        "id": "hy7s2kSEuWtl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_data = {\n",
        "    'English': [line for line in english_txt[0:1000]],\n",
        "    'German': [line for line in german_txt[0:1000]]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(raw_data, columns=['English', 'German'])\n",
        "\n",
        "train, test = train_test_split(df, test_size=0.2)\n",
        "\n",
        "train.to_json(\n",
        "    '/content/drive/MyDrive/ColabNotebooks/PyTorch/Datasets/train_de.json',\n",
        "    orient='records',\n",
        "    lines=True\n",
        ")\n",
        "test.to_json(\n",
        "    '/content/drive/MyDrive/ColabNotebooks/PyTorch/Datasets/test_de.json',\n",
        "    orient='records',\n",
        "    lines=True\n",
        ")"
      ],
      "metadata": {
        "id": "SjPkXZVLvHc8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spacy_eng = spacy.load('en_core_web_sm')\n",
        "spacy_ger = spacy.load('de_core_news_sm')\n",
        "\n",
        "def tokenize_eng(text):\n",
        "  return [tok.text for tok in spacy_eng.tokenizer(text)]\n",
        "\n",
        "def tokenize_ger(text):\n",
        "  return [tok.text for tok in spacy_ger.tokenizer(text)]\n",
        "\n",
        "english = Field(\n",
        "    sequential=True,\n",
        "    use_vocab=True,\n",
        "    tokenize=tokenize_eng,\n",
        "    lower=True\n",
        ")\n",
        "\n",
        "german = Field(\n",
        "    sequential=True,\n",
        "    use_vocab=True,\n",
        "    tokenize=tokenize_ger,\n",
        "    lower=True\n",
        ")\n",
        "\n",
        "fields = {'English': ('eng', english), 'German': ('ger', german)}\n",
        "\n",
        "train_data, test_data = TabularDataset.splits(\n",
        "    path='/content/drive/MyDrive/ColabNotebooks/PyTorch/Datasets',\n",
        "    train='train_de.json',\n",
        "    test='test_de.json',\n",
        "    format='json',\n",
        "    fields=fields\n",
        ")"
      ],
      "metadata": {
        "id": "srKQ7zxM_Ajw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "english.build_vocab(train_data, max_size=10000, min_freq=2)\n",
        "german.build_vocab(train_data, max_size=10000, min_freq=2)\n",
        "\n",
        "train_iterator, test_iterator = BucketIterator.splits(\n",
        "    (train_data, test_data),\n",
        "    batch_size=32,\n",
        "    device=device\n",
        ")"
      ],
      "metadata": {
        "id": "HrRVo_KK4mD_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in train_iterator:\n",
        "  print(batch)"
      ],
      "metadata": {
        "id": "W2XiZ7-050mL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "english = Field(sequential=True, use_vocab=True, tokenize=tokenize_eng, lower=True)\n",
        "german = Field(sequential=True, use_vocab=True, tokenize=tokenize_ger, lower=True)\n",
        "\n",
        "train_data, vaL_data, test_data = Multi30k.splits(\n",
        "    # root='/content/drive/MyDrive/ColabNotebooks/PyTorch/Datasets',\n",
        "    exts=(\".de\", \".en\"),\n",
        "    fields=(german, english)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "eL381-zrBM6Q",
        "outputId": "9a8c3bc4-43a1-4f23-bac1-6666b13c1b9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-708b1761b2d0>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mgerman\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mField\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequential\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_vocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenize_ger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlower\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m train_data, vaL_data, test_data = Multi30k.splits(\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/content/drive/MyDrive/ColabNotebooks/PyTorch/Datasets'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mexts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".de\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\".en\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchtext/datasets/translation.py\u001b[0m in \u001b[0;36msplits\u001b[0;34m(cls, exts, fields, root, train, validation, test, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'path'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         return super(Multi30k, cls).splits(\n\u001b[0m\u001b[1;32m    114\u001b[0m             exts, fields, path, root, train, validation, test, **kwargs)\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchtext/datasets/translation.py\u001b[0m in \u001b[0;36msplits\u001b[0;34m(cls, exts, fields, path, root, train, validation, test, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         train_data = None if train is None else cls(\n\u001b[0m\u001b[1;32m     66\u001b[0m             os.path.join(path, train), exts, fields, **kwargs)\n\u001b[1;32m     67\u001b[0m         val_data = None if validation is None else cls(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchtext/datasets/translation.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, exts, fields, **kwargs)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mexamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msrc_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m                 \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrg_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtrg_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0msrc_line\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg_line\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/ColabNotebooks/PyTorch/Datasets/multi30k/train.de'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "english.build_vocab(train_data, max_size=10000, min_freq=2)\n",
        "german.build_vocab(train_data, max_size=10000, min_freq=2)"
      ],
      "metadata": {
        "id": "uCJmxjzMClz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# spacy_en = spacy.load('en_core_web_sm')\n",
        "# spacy_ger = spacy.load('de_core_web_sm')\n",
        "\n",
        "# def tokenize(text):\n",
        "#   return [tok.text for tok in spacy_en.tokenize(text)]\n",
        "\n",
        "# quote = Field(sequential=True, use_vocab=True, tokenize=tokenize, lower=True)\n",
        "# score = Field(sequential=False, use_vocab=False)\n",
        "\n",
        "# fields = {'quote': ('q', quote), 'score': ('s', score)}"
      ],
      "metadata": {
        "id": "6s5oKTiUgaKu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, test_data = TabularDataset.splits(\n",
        "    path = '/content/drive/MyDrive/ColabNotebooks/PyTorch/Datasets/torchtext',\n",
        "    train = 'train.json',\n",
        "    test = 'test.json',\n",
        "    format = 'json',\n",
        "    fields = fields\n",
        ")"
      ],
      "metadata": {
        "id": "RusMFgjwjYhC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "quote.build_vocab(train_data, max_size=10000, min_freq=1)\n",
        "\n",
        "train_iterator, test_iterator = BucketIterator.splits(\n",
        "    (train_data, test_data),\n",
        "    batch_size=2,\n",
        "    device=device\n",
        ")"
      ],
      "metadata": {
        "id": "3UN8HTx_yH6C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in train_iterator:\n",
        "  print(batch.q)\n",
        "  print(batch.s)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aOT6V8PgyQ2d",
        "outputId": "5e6da917-25d7-4ef6-915f-1a701427830e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[10, 27],\n",
            "        [21, 29],\n",
            "        [ 4,  7],\n",
            "        [ 3, 26],\n",
            "        [ 6, 18],\n",
            "        [11,  2],\n",
            "        [17, 25],\n",
            "        [ 4,  1],\n",
            "        [ 3,  1],\n",
            "        [30,  1],\n",
            "        [28,  1],\n",
            "        [ 5,  1],\n",
            "        [13,  1],\n",
            "        [ 2,  1],\n",
            "        [ 9,  1],\n",
            "        [23,  1]])\n",
            "tensor([1, 0])\n",
            "tensor([[33],\n",
            "        [19],\n",
            "        [24],\n",
            "        [14],\n",
            "        [15],\n",
            "        [34],\n",
            "        [32],\n",
            "        [31],\n",
            "        [16],\n",
            "        [20],\n",
            "        [22],\n",
            "        [12],\n",
            "        [ 5],\n",
            "        [ 8]])\n",
            "tensor([1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R9Vg5mvn09cz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}